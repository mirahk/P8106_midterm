---
title: "p8106 midterm"
author: "Mirah"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(tidymodels)
library(splines)
library(mgcv)
library(pdp)
library(earth)
library(tidyverse)
library(ggplot2)
library(corrplot)
library(table1)

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```
# Midterm Project
### background
To gain a better understanding of the factors that predict recovery time from COVID-19 illness, a study was designed to combine three existing cohort studies that have been tracking participants for several years. The study collects recovery information through questionnaires and medical records, and leverages existing data on personal characteristics prior to the pandemic. The ultimate goal is to develop a prediction model for recovery time and identify important risk factors for long recovery time.
```{r}

#loading data set

load("Data/recovery.RData")

dat = dat %>% drop_na() %>% janitor::clean_names() %>% select(-id)

#no missing values
```

##Exploratory Analysis

Splitting up the data into a matrix of predictors and a vector of responses.
```{r}
#matrix of predictors, no recovery time
x_ea = model.matrix(recovery_time ~., dat)[, -1]
#vector of responses
y_ea = dat$recovery_time

data_ea = dat %>% 
  mutate(
    gender = case_match(
      gender, 
      1 ~ "Male", 
      0 ~ "Female"
    ), 
    race = case_match(
      race, 
      "1" ~ "White, non-Hispanic", 
      "2" ~ "Asian", 
      "3" ~ "Black, non-Hispanic", 
      "4" ~ "Hispanic"
    ), 
    smoking = case_match(
      smoking, 
      "0" ~ "No history", 
      "1" ~ "Formerly smoked", 
      "2" ~ "Currently smokes"
    ), 
    hypertension = case_match(
      hypertension, 
      1 ~ "Hypertension", 
      0 ~ "No hypertension"
    ), 
    diabetes = case_match(
      diabetes, 
      1 ~ "Diabetes", 
      0 ~ "No diabetes"
    ), 
    vaccine = case_match(
      vaccine, 
      1 ~ "Vaccinated", 
      0 ~ "Not vaccinated"
    ), 
    severity = case_match(
      severity, 
      1 ~ "Severe infection", 
      0 ~ "Not severe infection"
    )
  )

```

Creating a summary statistic table:
```{r}
skimr::skim(data_ea) %>%  dplyr::mutate(across(where(is.numeric), ~round(., 2))) %>%  select(skim_variable, numeric.hist, n_missing, numeric.mean, numeric.sd, numeric.p0, numeric.p50, numeric.p100) %>% knitr::kable()

exploratory_table = table1(~ gender + age + race + height + weight + bmi + sbp + ldl + smoking + hypertension + diabetes + severity + recovery_time |study, data=data_ea)

exploratory_table
```

Scatterplots of numeric variables and recovery_time:
```{r}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x_ea[, -c(2,3,4,5,6,7,11,12,15,16,17)], y_ea, plot="scatter", labels = c("", "Y"),type = c("p", "smooth"), layout = c(3,2))
```

Scatter plots don't show much of a trend. Bmi looks slightly parabolic. The rest are slightly linear.

```{r}
correlation = corrplot(cor(x_ea[, -c(2,3,4,5,6,7,11,12,15,16,17)],y_ea))
#correlation values and scatter plots show no linear correlations with the nummeric variables

#checking to see if predictors correlate
corrplot(cor(x_ea[, -c(2,3,4,5,6,7,11,12,15,16,17)]), type = "full", diag= FALSE)


```

Correlation plot supports that there is little relationship between predictors and the outcome. 

Based on a discussion with the team, we decided to remove outliers and then proceed with further exploratory analysis and model training.

```{r}
#box plots to show outliers
ggplot(data = dat, mapping = aes(y=recovery_time)) + geom_boxplot()

ggplot(data = dat, mapping = aes( x = study, y = recovery_time)) + geom_boxplot()


#histogram
hist1 = dat %>% 
  ggplot(aes(x = recovery_time)) + 
  geom_histogram(bins = 150)+
  labs(title = " Distribution of recovery time (days)")

#skewed 

#Removing outliers

outlier_coef = 1.5

outlier_upper = mean(dat$recovery_time) +outlier_coef* sd(dat$recovery_time)

outlier_lower = mean(dat$recovery_time) -outlier_coef* sd(dat$recovery_time)

dat_2 = dat %>% 
  filter(outlier_lower < recovery_time & recovery_time < outlier_upper)

#new histogram

hist2 = dat_2 %>% 
  ggplot(aes(x = recovery_time)) + 
  geom_histogram(bins = 150)+
  labs(title = " Distribution of recovery time (days)")


#looks way more normal

#to compare side by side
gridExtra::grid.arrange(hist1, hist2, nrow=1)
```
Histograms and box plots above show outliers. Histograms above show how the skew was reduced when outliers were removed.

```{r}
#exploratory plots now that outliers are gone:

skimr::skim(dat_2) %>%  dplyr::mutate(across(where(is.numeric), ~round(., 2))) %>%  select(skim_variable, numeric.hist, n_missing, numeric.mean, numeric.sd, numeric.p0, numeric.p50, numeric.p100) %>% knitr::kable()

exploratory_table = table1(~ gender + age + race + height + weight + bmi + sbp + ldl + smoking + hypertension + diabetes + severity + recovery_time |study, data=dat_2)

exploratory_table

#scatter plot 
#matrix of predictors, no recovery time
x_ea2 = model.matrix(recovery_time ~., dat_2)[, -1]
#vector of responses
y_ea2 = dat_2$recovery_time
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x_ea2[, -c(2,3,4,5,6,7,11,12,15,16,17)], y_ea2, plot="scatter", labels = c("", "Y"),type = c("p", "smooth"), layout = c(3,2))
```

##Model training

```{r}
#splitting data into training and testing 
set.seed(1234)

#data partition
data_split = initial_split(data = dat_2, prop = .8)

training_data = training(data_split)
test_data = testing(data_split) %>% as.vector()
```


```{r}
#training data
set.seed(1234)

#matrix of predictors, no recovery time
x_training = model.matrix(recovery_time ~., training_data)[, -1]
#vector of responses
y_training = training_data$recovery_time

#testing data
set.seed(1234)
#matrix of predictors, no recovery time
x_testing = model.matrix(recovery_time ~., test_data)[, -1]
#vector of responses
y_testing = test_data$recovery_time

```


```{r}
#using caret

set.seed(1234)
#knn
control = trainControl(method= "cv", number = 10)


fit.knn = train(x_training, y_training,
                method = "knn",
                trControl = control,
                tuneGrid = expand.grid(k=seq(from =1, to = 25, by = 1)))

ggplot(fit.knn)

knn.pred = predict(fit.knn, newdata = model.matrix(recovery_time ~ .,test_data)[,-1])

knn.te = mean((knn.pred - test_data$recovery_time)^2)

summary(fit.knn$finalModel)

#k=14
```

```{r}
#linear model
set.seed(1234)

lm.fit = train(x_training, y_training,
               method = "lm",
               trControl = control)

lm.fit$bestTune
summary(lm.fit)

lm.pred = predict(lm.fit, newdata = model.matrix(recovery_time ~ .,test_data)[,-1])

lm.te = mean((lm.pred - test_data$recovery_time)^2)

summary(lm.fit$finalModel)
```

```{r}
#ridge regression
set.seed(1234)
ridge.fit <- train(x_training,y_training,
                   data = training_data,
                   trControl = control,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0,
                                          lambda = exp(seq(10, -5, length=100))))

plot(ridge.fit, xTrans = log)

#best lambda
ridge.fit$bestTune

#Coefficients in final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)

ridge.pred = predict(ridge.fit, newdata = model.matrix(recovery_time ~ .,test_data)[,-1])

# test error
ridge.te = mean((ridge.pred - test_data$recovery_time)^2)
```

Dimension reduction
```{r}
#PCR
set.seed(1234)
pcr.fit <- train(x_training, y_training,
                 method = "pcr",
                 tuneGrid = data.frame(ncomp = 1:18),
                 trControl = control,
                 preProcess = c("center", "scale"))

predy2.pcr2 <- predict(pcr.fit, newdata = x_testing)

pcr.te = mean((y_testing - predy2.pcr2)^2)

ggplot(pcr.fit, highlight = TRUE) + theme_bw()

summary(pcr.fit$finalModel)
```


```{r}
#lasso
set.seed(1234)
lasso.fit <- train(x_training, y_training,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(-2, -6, length=200))),
                   trControl = control)

plot(lasso.fit, xTrans = log)

lasso.fit$bestTune

# coefficients

coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)

#test error

lasso.pred <- predict(lasso.fit, newdata = x_testing)

lasso.te = mean((y_testing - lasso.pred)^2)

summary(lasso.fit$finalModel)
```


```{r}
#PLS
set.seed(1234)
pls.fit <- train(x_training, y_training,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:18),
                 trControl = control,
                 preProcess = c("center", "scale"))

predy2.pls2 <- predict(pls.fit, newdata = x_testing)

pls.te = mean((y_testing - predy2.pls2)^2)

ggplot(pls.fit, highlight = TRUE)

summary(pls.fit$finalModel)
```


```{r}
#elastic net
enet.fit = train(x_training, y_training,
                 method = "glmnet",
                 tuneGrid = expand.grid(alpha = seq(0, 1,length = 21),
                                        lambda = exp(seq(6, 0, length = 100))),
                 trControl = control)

enet.pred <- predict(enet.fit, newdata = x_testing)

enet.te = mean((y_testing - enet.pred)^2)

summary(enet.fit$finalModel)
```


```{r}

#GAM
set.seed(1234)
gam.fit = train(x_training, y_training,
                 method = "gam",
                 tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
                trControl = control)

gam.fit$bestTune

gam.pred <- predict(gam.fit, newdata = x_testing)

gam.te = mean((y_testing - gam.pred)^2)
```

```{r}
gam.fit$finalModel

summary(gam.fit$finalModel)
```

```{r}
#MARS
mars_grid <- expand.grid(degree = 1:4,
nprune = 1:20)

set.seed(1234)
mars.fit <- train(x_training, y_training,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = control)

ggplot(mars.fit)

mars.pred <- predict(mars.fit, newdata = x_testing)

mars.te = mean((y_testing - mars.pred)^2)
```

```{r}
mars.fit$bestTune
```

```{r}
coef(mars.fit$finalModel)

summary(mars.fit$finalModel)

```


```{r}
plot(gam.fit$finalModel)
```


```{r}
#which is better
rs = resamples(list(knn = fit.knn, lm = lm.fit, elastic_net = enet.fit, mars = mars.fit, gam = gam.fit,pcr=pcr.fit, pls=pls.fit, ridge = ridge.fit, lasso = lasso.fit))

rmsesum = summary(rs, metric = "RMSE")

bwplot(rs, metric = "RMSE")


```

```{r}
#model tables
model = c("linear", "Knn", "Ridge", "PCR", "PLS", "Lasso", "Elastic Net", "GAM", "MARS")

test_error = c(lm.te, knn.te, ridge.te, pcr.te, pls.te, lasso.te, enet.te, gam.te, mars.te)

mean_RMSE = c(mean(rmsesum$values$`lm~RMSE`),
              mean(rmsesum$values$`knn~RMSE`),
              mean(rmsesum$values$`ridge~RMSE`),
              mean(rmsesum$values$`pcr~RMSE`),
              mean(rmsesum$values$`pls~RMSE`),
              mean(rmsesum$values$`lasso~RMSE`),
              mean(rmsesum$values$`elastic_net~RMSE`),
              mean(rmsesum$values$`gam~RMSE`),
              mean(rmsesum$values$`mars~RMSE`))

mean_MAE = c(mean(rmsesum$values$`lm~MAE`),
              mean(rmsesum$values$`knn~MAE`),
              mean(rmsesum$values$`ridge~MAE`),
              mean(rmsesum$values$`pcr~MAE`),
              mean(rmsesum$values$`pls~MAE`),
              mean(rmsesum$values$`lasso~MAE`),
              mean(rmsesum$values$`elastic_net~MAE`),
              mean(rmsesum$values$`gam~MAE`),
              mean(rmsesum$values$`mars~MAE`))

mean_rsqrd = c(mean(rmsesum$values$`lm~Rsquared`),
              mean(rmsesum$values$`knn~Rsquared`),
              mean(rmsesum$values$`ridge~Rsquared`),
              mean(rmsesum$values$`pcr~Rsquared`),
              mean(rmsesum$values$`pls~Rsquared`),
              mean(rmsesum$values$`lasso~Rsquared`),
              mean(rmsesum$values$`elastic_net~Rsquared`),
              mean(rmsesum$values$`gam~Rsquared`),
              mean(rmsesum$values$`mars~Rsquared`))


model_result = data.frame(
  Model = model,
  test_error = test_error,
  mean_RMSE = mean_RMSE,
  mean_MAE = mean_MAE,
  mean_rsqrd = mean_rsqrd
) %>%  mutate(test_error = round(test_error,2),
              mean_RMSE = round(mean_RMSE, 2),
              mean_MAE = round(mean_MAE, 2),
              mean_rsqrd = round(mean_rsqrd, 4))

model_result
```


